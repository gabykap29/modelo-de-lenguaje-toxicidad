# Modelo de Toxicidad

Este proyecto consiste en un modelo de toxicidad que utiliza TensorFlow.js y el modelo de TensorFlow Hub para detectar la toxicidad en texto.

## Funcionamiento

El modelo carga un modelo preentrenado de toxicidad y realiza la clasificación de las frases proporcionadas como entrada. Las frases pueden ser ingresadas a través de un formulario de entrada de texto en una página web.

## Tecnologías utilizadas

- TensorFlow.js
- TensorFlow Hub
- HTML
- CSS
- JavaScript

## Instalación

1. Clona este repositorio o descarga el código fuente.
2. Asegúrate de tener instalado un servidor web local o un entorno de desarrollo adecuado para ejecutar el código.
3. Abre el archivo `index.html` en tu navegador web.

## Uso

1. Escribe una frase en el campo de entrada de texto.
2. Haz clic en el botón "Enviar".
3. El modelo clasificará la frase como tóxica o no tóxica y mostrará el resultado en forma de alerta.

## Ejemplo

Puedes probar el modelo ingresando diferentes frases en el campo de entrada de texto y observando las alertas generadas por el modelo.

